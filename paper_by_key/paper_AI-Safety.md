# Papers with Keyword: AI-Safety

- [Qwen3Guard Technical Report](https://arxiv.org/pdf/2510.14276)
    -  Qwen Team
    - ğŸ›ï¸ Institutions:  Qwen Team
    - ğŸ“… Date: Oct. 16, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [Misc]
    - ğŸ”‘ Key: [benchmark], [evaluation], [AI-Safety], [Model]
    - ğŸ“– TLDR: Existing LLM safety classifiers are limited by binary labels and delayed detection. We introduce Qwen3Guard, a multilingual safety model series featuring: (1) Generative Qwen3Guard for fineâ€‘grained triâ€‘class classification (safe/controversial/unsafe). (2) Stream Qwen3Guard for realâ€‘time, tokenâ€‘level monitoring during streaming generation.

- [Introducing v0.5 of the AI Safety Benchmark from MLCommons](https://arxiv.org/abs/2404.12241)
    -  MLCommons AI Safety Working Group (WG)
    - ğŸ›ï¸ Institutions:  MLCommons AI Safety Working Group (WG), et al.
    - ğŸ“… Date: May. 13, 2024
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [Misc]
    - ğŸ”‘ Key: [benchmark], [evaluation], [AI-Safety], [AI-systems]
    - ğŸ“– TLDR: This paper presents v0.5 of the AI Safety Benchmark by the MLCommons AI Safety Working Group, designed to evaluate safety risks of chat-tuned AI systems. Version 0.5 covers a single English chat use case with typical, malicious, and vulnerable personas. It introduces 13 hazard categories, with tests for seven, totaling 43,090 prompts. The release includes benchmark specifications, a grading system, the ModelBench evaluation platform, an example report, and documentation of limitations. Version 1.0, planned for late 2024, will offer broader safety insights.
